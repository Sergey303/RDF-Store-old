Концепции, лежащие в основе универсального индекса

Неизменяемый индекс IndexViewImmutable<Tkey> сделан как некоторая идейная основа. Он больше не используется, 
воспроизводятся лишь элементы решений. В дальнейшем, будем считать, что таблица и индекс обладают динамикой.
Соответственно, нужно доопределить опорную таблицу и базовое индексное построение необходимыми элементами.

К интерфейсу опорной таблицы надо добавить редактирующие изменения: добавление элемента и убавление элемента. 
Добавление в чем-то будет функционально дублировать Build, но это существенно другое действие. Убавления вообще
не было. Еще нам понадобится фильтр, убирающий из потока указателей на элементы таблицы, те из них, которые 
отмечены как уничтоженные. В дальнейшем, нам понадобится менеджер индексов, задача которого будет выполнять 
коррекцию всех индексов, при выполнении операции добавления (а может, и убавления?). Наверное, такой менеджер
нужно организовывать через событие (event). Пока этот момент пропустим. 

Теперь подумаем о спецификации индекса. Что изменяется при добавлении динамики? Как уже было зафиксировано,
индекс состоит из неизменяемой части и изменяемой (динамической) части. Неизменяемая часть (вроде) уже 
специфицирована. А изменяемая? Или общая? Вроде все то, что определено для неизменяемой, нужно и для изменяемой. 
Существенное добавление должно быть связано с отработкой операций редактирования. Хотя бы добавления элемента
в опорную таблицу. Что-то вроде OnAppendElement(...).

Main2() - это промежуточное решение, в котором создается опорная таблица через класс TableView, таблица 
заполняется данными. Далее, строится неизменяемый индекс, в данной программе - на строковую колонку. И наконец,
индекс тестируется на предмет получения данных. Разница в Main1() и Main2() в двух моментах. Первый - 
используется "боевой" вариант опорной таблицы и, второй - поиск ведется по расширенному на половину диапазону,
а значит, успешных нахождений - приблизительно 2/3 от 1000.

Следующее изменение каснется индекса. Теперь нужно сделать динамический индекс, который будет содержать 
динамическую таблицу (словарь) и неизменяемый индекс. И будет отрабатывать запросы. Делаю DynamicIndex.

Несколько запутался в переметрических типах и интерфейсах. Попробую проанализировать жизненный цикл универсальной
изменяемой таблицы с индексами. Вначале создается коннектор, который либо дает подсоединение к существующей опорной 
таблице, либо ее создает и дает к ней подсоединение. Не обеспечивается фукнциональная полнота таблицы, если она
не заполнена данными. (??? - может все-таки обеспечить?). По имеющейся индексной логике, индекс можно создать в 
когда он потребуется и можно уничтожеть, когда надобность в нем отпадет. С точки зрения подключения к базе данных,
индекс - ячейка, но по ячейке восстановить особенности устройства индекса не видно как. Так что оставим задачу
управления индексами за потребителем таблицы или базы данных. Что это означет? Когда мы коннектимся, мы должны знать
особенности индексов, которые создавались ранее. Получается, что надо коннектиться и к индексам. Возможюно, проверяя
наличие файла (ов), но не более того. Итак, программа запущена, выполняем Connect. Если базы данных еще нет, создаем 
пустышку. Коннектимся к базе данных. Теперь можно ее построить Build(), т.е. заполнить начальными данными. Пока будем
считать Build - однократным действием, всегда начинающимся с очистки Clear() базы данных. С данной таблицей уже можно:
1) Перебрать неуничтоженные элементы; 2) Добавить элемент; 3) Уничтожеть элемент. Вполне приличная себе 
функциональность...     

Но (в смысле "и"!), к опорной таблице можно приделывать индексы и можно их убирать. Соответственно, индекс может уже
существовать или еще нет. К нему также надо "коннектиться". В принципе, это можно сделать с вух сторон. Либо создать 
индекс, указав опорную таблицу, либо каким-нибудь методом CreateIndex(), работающим от таблицы. Второе кажется не 
очень хорошо, поскольку пока для создания индекса надо много что указать, в том числе тип. Пойдем по первому пути.
Что-нибудь вроде имеющегося: 
IIndexImmutable<string> s_index = new IndexViewImmutable<string>(path + "s_index")
   {
      Table = table,
      KeyProducer = va => (string)((object[])(((object[])va)[1]))[0]
   };
Генератор ключа выглядит ужасно, но пока именно так...
Соответственно, создание индекса может сделать отметку в таблице. И тогда таблица начнет отрабатывать редактирующие
операторы: Clear(), Build(), AppendValue(), Delete...
Естественно, связь индекса с таблицей не прерывается и прямо индекс можно сделать Drop() или Remove(). Вроде все 
склеивается.

Устроив интерфейсы и приведя имеющиеся решения к этим интерфейсам, пора сделать новую реализацию опорной таблицы
и индексов. Для этого, запускающую программу сменю на Main3(). Буду делать TableView и DinamicIndexUnique. Возможно, 
в дальнейшем, уникальность ключевого значения будет задаваться булевским параметром.

Сделал небольшие модификации в оперной таблице TableView, необходимые для включения индексов в работу таблицы. Теперь
надо порассуждать о включаемом индексе. Я такой сейчас готовлю: DynamicIndexUnique<Tkey, IndexImmut>. Он получается
аж с двумя параметрами, это не считая возможных других, в дальнейшем. Параметр типа ключа - обычный. Но также задается
параметр неизменяемого индекса для задания индексного массива. По нашей идее он неизменяемый до следующего 
переформирования. Предположим, индексный массив задается "снаружи" и "прилепляется" через свойство. В этом могут быть
некотрые проблемы из-за "разбегания" генератора ключа (будет определяться дважды). Но посмотрим...

20150331 11:07
Удалось собрать базовое решение. То есть: 1) опорная таблица содержит не только себя, но и ссылки на активированные 
индексы. Это позволит автоматически отслеживать изменения в таблице, делая изменения в индексах. 2) Индексный массив
простой (будут и другие решения) и неизменяемый. 3) Индекс объединяет словарь входов и индексный массив. Испытания
пока подтверждают ранее достигнутые результаты. 

Следующие шаги:
а) Сделать вариант индекса, не являющегося Unique. 
б) Проверить работу индекса на целых значениях.
в) Внедрить понятие "выровненное ключевое значение" и реализовать индекс в виде пары {offset, key_value}.
г) Внедрить понятие "полуключ" и реализовать индекс в виде аналогичной пары.
д) Внедрить понятие "шкала" и добавить шкалу в реализации.

 Пункт а) попробую сделать "дешево" - введу параметр unique в инициализацию индекса.

20150403 12:07
Сделал через параметр unique, вроде без потери простоты реализации. Теперь пришло соображение о моменте,
который я не учитывал. Дало в том, что основные рассуждения насчет поиска касаются поиска первого или всех
тех, ключевое значение которых совпадает с образцом. Но существует и другая поисковая ситуация. Надо найти
первый или всех таких, которые соответствуют нулю при задании уровня глубины. 

20150404 09:12
Так вчера и не смог напрячься на созидательную работу. Сегодня - полон решимости, надо действовать. 

Момент, который является принципиальным и который я продумывал - другая схема выполнения поиску - поиск 
по функции "глубины". То есть, на каком-то уже построенном индексе задается функция, отображающая элементы
опорной таблицы в числа по принципу: 0 - "поверхность", '+' - значения "больше" заданного порога, '-' - 
значения "меньше" порога. Связь с уже построенным инексом с том, что функция должна быть согласованной с
функцией ключа и с заданным на ключах отношением сравнения. Частным, но не единственным вариантом такой 
фукнции уровня будет что-то вроде: 
Func<Tkey, int> Level = key => key.CompareTo(key0);
Соответственно, поиск по функции уровня должен выдавать все значения (или первое значение), такие, что 
функция уровня на них равна нулю. Согласованность функции уровня с конкретным индексом позволяет 
воспользоваться бинарным поиском на этом индексе. В указанном частном случае, поиск по функции уровня 
совпадает с поиск значений с заданным ключем. Но в общем случае, этот поиск дает более широкое множество
значение, соответствующих "соседним" ключам, "неразличимым" в метрике уровнего поиска. Согласованность
функции уровня с индексом обеспечивает (долна обеспечивать) непрерывный характер, т.е. интервал, для этого 
более широкого множества.

Существенная проблема появляется при появлении слабой динамики. Статическая часть индекса, для которого 
определен (нетривиальный) поиск по уровню, т.е. индексный массив, хорошо соответствуют задаче и бинарный
поиск выполняется хорошо. А вот словарь, накапливающий пары ключ-оффсет или ключ-множествооффсетов, уже 
плохо соответствуют.   
			  
Возможно, если несколько модифицировать уровневый подход, можно и всю конструкцию грамотно изложить. Но 
пока не получается. Идея рассмотрния следующая: есть единый индекс с последовательным упорядочиванием 
по одному полю, потом по другому, потом по третьему. Ключ, в данном случае становится весьма композитным -
что-то вроде кортежа из трех значений. И для базовой ситуации, когда задается ключ полностью, т.е. в
данном случае в виде значений трех полей, все ранние ключевые построения "работают". Но если захотеть 
сделать выборку по значению неполностью заданного ключа, напр. если заданы первые два поля, то мы 
приходим к ситуацией, названной в данном разделе "поиск по функции уровня". Для функции уровня, "работает"
только бинарный поиск. да и то, только в индексном массиве. А словарь придется перебирать поэлементно. 
Можно предположить, что при другом способе задания поискового критерия, возможно в виде каких-то 
факторизаций, может появится более экономная и эффективная теория. По крайней мере стоит заметить, что
вот этих уровневых функций может быть много. У одного заданного индекса.

Подход, который я попытался наметить в предыдущем абзаце, можно было бы назвать чем-нибудь вроде "ступенчатое
индексирование". Тут есть над чем работать, но это потом. Сейчас попробую зафиксировать поиск по функции
глубины.

20150405 10:32
Я все думаю о ступенчатом индексировании. Не очень получается, но явно что-то в этом есть. Итак, пусть есть
цепочка функций, удовлетворяющих условиям ключевого индексного использования. Например, это могут быть 
целочисленные коды. Используем их для пострения индекса следующим образом: упорядочивание идет по первому  
коду, при равенстве, используется второй и т.д. Идея, которую мы хотим проявить, заключается в том, что
пи таком упорядочивании эффективно решается задача поиска по первому коду, по первому и второму и т.д.
Обычным делением отрезка пополам. 

Теперь мы сделаем "трюк". Мы выделим случаи, когда для одного значения первого ключа имеется слишком много 
вариантов. Эти случаи мы выстроим в пары: значениепервогоключа-индекс2. Где индекс2, это также цепочечный 
индекс, но с цепочкой ключ2-ключ3-... Тогда при поиске по первому ключу, надо будет проверять нет ли по 
этому значению частного варианта и если есть, он сразу даст решение. Если идет поиск по первому и второму
ключу, при совпадении первого ключа с частным случаем, производится поиск в индексе найденной пары. 
Метод рекурсивно продолжается. 

Пока мы при поиске выигрываем ТОЛЬКО в потенциальной быстроте нахождения частного случая. Потому что в 
остальном, поиск базируется на дихотомии. Но если подключить шкалирование, то ситуация несколько другая. 
При шкалировании, нахождение первого диапазона будет произовдиться одинаково, грубо говоря - за одно 
обращение. А вот для частного случая мы также можем организовать шкалу и на этом существенно выиграть. 

А что у нас в шкале? Там индексом отмечается ячейка, содержащая диапазон для данных значений индексного 
(?) ключа. А как это сочетается с цепочечной индексацией. Пусть код индексного ключа является 
конкатенацией и обрезанием кодов цепочки. Нет уверенности в равномерной плотности таких модифицированных 
кодов. 

Теперь пора работать конструктивно. Во-первых, намечу или даже реализую поиск по фукции уровня. Сейчас
наличие его не существенно, но чтобы не висел...

А что существенно, так это перенести наработку индексов с ключами/полуключами в данный пакет.
Попробую разделить варианты ключа и полуключа. 

Как промежуточный этап, я сделал вариант стандартного индекса на целочисленную колонку: Main4(). Вроде
заработал, время похоже на правду: 314-324

Теперь сделаю индекс с ключем - IndexKeyImmutable. Теперь попробую применить для целочисленной колонки

20150406 07:47
Теперь, аналогично, попробую сделать IndexHalfkeyImmutable.

20150407 07:56
Полуключ также сделал и вроде он работает. Теперь надо сделать шкалу. Попробую организовать это дело
так: шкала будет классом, собственно массив может быть построен по запросу, класс приклепляется к
неизменяемому индексу и используется, если не null. Как-то так...

Пока не ясно как формировать в шкале границы диапазона. В принципе, если исходить из формирования
шкалы на основе минимального и максимального значений, вопросом является как их вычислять. Можно 
это делать при формировании значения шкалы, но одним проходом будет меньше если вычислять...
Сейчас сообразил, что есть более простой способ определения минимального и максимального. Надо 
просто посмотреть в первый элемент базового индекса и в последний. Индексный массив же ОТСОРТИРОВАН!

20150409 09:52
Исправил ошибки и заставил шкалу работать. Иногда получается эффектно (15-40 мс. на тусячу запросов).
Собственно, при данной схеме существенно быстрее уже не получится, потому что такие величины означают 
то, что делается разовое количество обращений к диску. 

Сегодня сообразил простую вещь, в шкале нет необходимости хранить количество (number), достаточно 
хранить только индекты начал (start). Это потому, что количество легко получается вычитанием соседних 
стартовых номеров. А это дефицитная память...  
 
Проведенные эксперименты показали, что эффективность шкалы может быть почти предельная при существенно 
меньших размерах, чем полное для индекса число элементов. Этот оптимум между скоростью и размером
шкалы я устанавливаю в 1-2%. Сейчас, дефолтное значение шкалы буду вычислять как размер индексного
массива, деленный на 64. 

Теперь надо переименовать шкалу в ScaleMemory и сделать ScaleCell. Но сначала, уменьшу раз0мер шкалы 
вдвое убрав оттуда number. 

20150410 04:51
Несколько не удовлетворен организацией встраивания шкалы в неизменяемый индекс. Но, в принципе, это 
сделано и, похоже, работает. Не доделанными являются операции редактирования. Более высокий уровень 
требований - в том, чтобы автоматически перевычислялись индексы в фоновом режиме. И еще чтобы аккуратнее
решались вопросы разогрева. Мысль по этому поводу такая: произошел "холодный" запуск, система, хоть и 
не быстро (100 доступов в сек.), но начинает выполнять запросы. Одновременно, запускается первый уровень 
"разогрева" и выполняется в фоновом режиме. После выполнения первого разогрева, можно помечтать о 
следующем уровне, когда структуры более "жестко" переводятся в оперативную память. Пока подобной 
универсальной схемы не найдено, но мысли брезжут...

Рассуждая о последнем упомянутом моменте, появилось такое соображение: Можно статические ячейки, а их, 
как правило немало, переводить на потоки байтов. То есть, берешь ячейку, узнаешь ее размер в байтах и 
заводишь массив байтов соответствующего размера и копируешь одно в другое. А потом переключаешься с 
базовой ячейки на временно созданную. Не совсем понятно как переключаться в динамике работы системы. 
Но что-то в этих идеях есть... Надо бы попробовать соорудить копию ячейки в оперативной памяти и
померить ее характеристики. 

20150414 08:05
При попытке сделать кодированние для реализации триплетов, я наткнулся на ряд недоработок и недопониманий.
Кое-какие доработки были произведены, но сейчас я пересматриваю концепцию реализации таблицы имен. Я ее
хочу сделать в инфраструктуре универсального индекса. Проведу рассуждения по поводу желаемой реализации.
Одной из наиболее существенных недоработок предыдущего является отсутствие слабой динамики. Буду делать 
слабую динамику по стандартной схеме. Вообще-то есть сомненения по поводу необходимости уничтожения кодов,
но добавление кодов обязательно. 

Итак, без стандартной опорной таблицы, имеющей колонки deleted (это инфраструктура), code, id, похоже не
обойтись. И не буду обходиться... Была устойчивая мысль, что колонка code не обязательна для 
последовательного присвоения кодов, что номер элемента может быть этим значением. Но не получается.
Точнее, не совсем получается. Для поиска по идентификатору, при стандартной схеме, выстраивается индекс
с offset'ом на опорную таблицу и, возможно, полуключем. А где в итоге найти код? Альтернативным решением
могло бы быть выстраивание специализированного индекса, в котором вместо offset'а используется код. А по
коду, в другом индексе, мы получаем (зачем-то) доступ к записи. Но это будет отходом от инфраструктуры, 
чего на этом этапе делать бы не хотелось.

Итак, опорная таблица и два индекса - по строковому идентификатору и по коду. Оба индекса имеют признак
unique - биекция! Все делается стандартными средствами инфраструктуры. Можно даже использовать равномерность 
кодов - просто в индексе коды не храним и индексный массив не сортируем. Не хватает этого частного случая
для универсального индекса, об это надо будет подумать еще.   

В определенном смысле ключевым моментом является организация ввода данных порциями. Под вводом порциями
я подразумеваю разбиение входного потока добавляемых идентификаторов на отдельные порции с целью оптимизации
характеристик ввода. Почему это не было критично ранше и не поддерживается инфраструктурой? Похоже, это
связано с положением об уникальности (unique) строк и кодов. А во входном потоке может быть много повторов. 
Вводя все, мы можем породить слишком большие данные, а после сортировки придется их очищать от одинаковых
строк. В то же время, ввод единичными элементами, будет требовать проверок на каждом элементе и может
отрицательно повлиять на производительность ввода. 

Опорный массив и два индекса. Один надо будет сделать специальным - равномерным. Эффективная схема индексации
строкового столбца заключается в использовании полуключа. Теперь проанализируем вопрос ввода порциями. 
Реально порцию можно просто добавить в конец опорного массива. Одновременно, можно добавить offset'ы в
индекс по коду. Осталось изменить индекс по строковому столбцу. Интересно, а сдесь можно было бы использовать
стандартное слияние? Сначала отсортировать, потом слить? Все несколько усложняется из-за все той же уникальности.
Не получается просто добавлять. И потом я формирую словарь по имеющимся в порции идентификатором. 

Начнем снова. Порция - множество идентификаторов. Можно прямо "множество" и можно превратить его в отсортированный
массив. Теперь начинается слияние. Идем по строковому индексу


20150414 11:39
Итак, задача состоит в том, чтобы в инфраструктуру универсального индекса внедрить элементы,
которые позволят (легко) собирать базы данных типа таблиц имен. 

Общее представление о реализации таблицы имен заключается в следующем. Есть опорная таблица
со стандартными свойствами: поле deleted, элементы, состоящие из кода и строки. Также есть
два индекса по полю кода и по полю строки. Индексы имеют некоторые особенности. Индекс кода
не требует собственно кода и не требует сортировки - только офсеты. Индекс строковой колонки
- самый обычный, с использованием полуключа. В дальнейшем, думаю не будет ограничений в 
использовании шкалы. Но его особенность в дополнительном методе ввода - ввода потока строк
порциями. Попробую сформулировать метод в нужной для инфраструктуры абстракции. Индекс 
строится на основе ключа типа Tkey и целочисленного полуключа (хеша). Метод, который мы 
анализируем, есть метод индекса с признаком unique. Для текущего индекса 
(IndexHalfkeyImmutable) определяется метод 

Предыдущий анализ показал, что требуется сделать две существенные добавки. Первая
  
20150416 09:52
Хотя я вчера и не писал, работа велась и я сумел переписать ключевой метод 
        public Dictionary<string, int> InsertPortion(IEnumerable<string> s_flow)
Теперь надо его отладить. Немного побаиваюсь, поскольку логика программы, хоть и простая, но
имеет особенности. И очевидного способа отслеживания корректности результата я не знаю.
Кстати, я подумал, что этот метод не достаточно коррелирует с другими методами класса.
В частности, начинать добавление порции видимо надо с предположения о том, что в словаре
есть добавления и сначала слить добавления с индексными массивами. Точнее, надо бы иметь 
сливание из трех источников. Как-то я писал отдельно процедуру слияния, надо бы восстановить
и начать пользоваться.

Надо также внимательно просмотреть жизненный цикл шкалы. В условиях большой и малой динамики.
5 2 9 3 6 8 4 7 0 1 

Вроде заработал ввод порциями. Как всегда, штук 7 ошибок пришлоть найти и исправить...

20150417 06:22
Вчера похоже действительно программа заработала. Удалось довольно легко выполнить создание
таблицы имен для 1, 10, 100 млн. идентификаторов общего потока. На 1 млрд. возникли проблемы
- стало медленно или очень медленно. И вроде не из-за свопинга. Я запустил задаюу на ввод
25 порций по 40 млн. в порции, причем в диапазоне 1 млрд., так что наложений в потоке должно
быть мало. И вот уже часов 10 обрабатывает рабочий компьютер, уже близко к завершению, но не 
завершилось. Хочу начать разбираться в том, в каких местах происходят большие временные
затраты. 

Похоже, "планку" в 100 млн. имен, взять будет достаточно просто (и 150 млн.), а вот 1 млрд.
уже проблематично. Вроде и вводит, возможно даже правильно, но очень медленно. Уже более 12
часов, правда процесс ввода находится на последней порции (из 25). Оперативная память не 
слишком "напряшалась" (4-5 Гб), но что-то ввод держит...

Следующим вопросом является автономное построение индексов. То есть, по опорной таблице,
надо построить индексы. Посмотрю в код. Что уже предусмотрено, а что еще надо сделать.

20150530 08:22
Изучение особенностей решения по реализации RDF, породили сомнения, сомнения породили
беcсонницу, беcсонница породила новые идеи. Так вот одна идея выглядит интересной, попробую
ее сформулировать и может даже проверить. 

Если говорить конкретно, то сути идеи в следующем. У нас есть субъекты, предикаты и объекты.
Теперь попробуем выделить предикаты в отдельную категорию. Пусть есть список (может шкала)
предикатов, возможно отсортированных. И в этом списке фиксируется начало серии с одним 
предикатом и количество триплетов в серии. В общем - диапазон. А сами серии можно (вторично)
сортировать по другому признаку. По субъекту или объекту. А потом можно делать выборки по ps,
po, p, s, o. Немножко дополнительного перебора будет при проверке на spo. Кстати, в последнем 
случае, сначала можно определить мощность множеств проверки с то или другой стороны и выбрать
меньшее.

Так что - идея заменить много (5-6) индексов на 2? Может быть... А еще эффективность. Это 
неплохая идея.

Сначала посмотрю на то, что представляет собой шкала. Может какие-то соображения придут в
голову?

Шкала не подходит. Подходит обычный индекс с вторичным сортировочным критерием. Можно, 
например, сначала установить критерием сортировки предикат и упорядочить индекс 
группами по равным предикатам. Если мы зафиксируем соотвествие предикат-диапазон,
то далее, можно сменить критерий на другой, напр. на субъект, можно каждый диапазон 
упорядочить. А поиск выполнять в диапазонах. Такая схема больше подходит для 
IndexKeyImmutable. То есть нужно, чтобы для триплетов было целочисленное кодирование. 
Для упорядочения по предикату не подходит (плохо подходит) вариант с полуключем. Это
из-за статистики. Множество отношений будут давать 0 для стравнения полуключа и тогда 
надо привлекать вычисление ключа, т.е. обращаться к основному массиву.

Зато, хотя бы теоретически, можно работать в комбинации ключ-полуключ для вторичного 
индекса. 

Еще один момент, который хотелось бы использовать это возможность не выполнять
первичную сортировку в случае, если она была уже сделана. Действительно, если 
в качестве первично отсортированного индекса взять "чужой" индекс, то будет все нормально.
Экономия может быть заметной. 

Как такой индекс представлять? Для него нужны две функции и указание какой характер у 
вторичного индекса - ключ или полуключ. 

Еще одна проблема - шкала для вторичного индекса. В принципе, не для каждого диапазона можно
создавать шкалу. Скажем, только для самых больших. Некоторым подспорьем является то, что 
можно сделать шкалу в оперативной памяти. 

Таким образом, структура индекса может выглядеть следующим образом: 
1) Индексный массив, в котором имеется последовательность пар: offset элемента опорной 
таблицы, вторичный ключ-полуключ элемента
2) Диапазонный индекс, работающий по первичному ключу. Этот индекс является последовательностью
записей из значения первичного ключа и диапазона элементов индексного массива, для которых 
справедлив данный ключ.

Из диапазонного ключа можно будет делать втруктуру оперативной памяти в которой к
записе добавляется шкала данного диапазона. Это потом...

Пока непонятно как реализовывать слабую динамику. Прикинем. Пусть есть такой индекс. Какую 
"услугу" предоставляет индекс "внешнему миру". Несколько. Выдать все записи, для которых
задан первичный индекс. p1, p1p2, p2. Думаю, если в словаре хранить хотя бы offset записи,
уже можно делать добавочные действия по слабой динамике. 

Измерим производительность преобразования строк в коды.

Получилось 693 мс. на 10 тыс. Надо бы ускорить. Единственный способ, который приходит в 
голову - сделать шкалу в ОЗУ. Посмотрю как это можно или нельзя сделать. 

После такой замены получилось 528 мс. Не слишком улучшилось, но появились "хлопоты" связанные 
с необходимостью формирования шкалы. 
После долгих "мучений" и исправлений своих же ошибок, получилось 527 мс. Как-то грустно...
Уменьшив фактор для шкалы до 8 получаем 424 мс. Тоже не ахти...

20150601 07:22
Вот и лето пришло - День защиты детей! Вроде и погода наладилась...

Сделал 1-е измерение по эффективности работы полуиндекса в таблице имен. Я остановился в 
вычислении множества удовлетворяющих совпадению с ключем на обращении к шкале. Диапазон получен!
После этого формируется пустой результат. Получилось 5 мс. на 10000 запросов! Это для шкалы в 
памяти. Сейчас посмотрю что будет со шкалой на диске. 

Получилось 65 мс. на 10 тыс. Это значит, что заменять шкалу на ScaleMemory можно, но это мало что 
дает - процентов 10-15 экономии. А неудобства есть... 

А вот из чего складывается почти 700 мс. на 10 тыс. для GetAllByKey(dia.start, dia.numb, key) - 
хорошо бы разобраться. 

Итак, 694 с этой "дурацкой" процедурой и 68 - без. HalfProducer почти не добавляет (меньше 10 мс).
Еще немножно (до 82) добавляется при построении Sparql-дерева первого выбора.
BinarySearchAll() добавляет до 630 мс. А все - опять 693 мс. Самое напряженное место выявлено.
А если его немного поизменять?

75 - без поиска.
314 - просто сканирование вместо поиска.
269 если до первого сопадения по полуключу
274, 261 то же самое, но в виде формулы
291 немного переделанная формула
297 сначала проверяется на то, что полуключ <= заданного
223 - если эту проверку заменить на .TakeWhile(va => (int)va[0] > hkey) 
220 - практически не добавила время дополнительная проверка на равенство ключей
231 - в конце переход к PaEntry
226 - Вроде - все... Правда собственно поиск перестал работать. Надо искать ошибку. 

Пойду на работу.

Это были ошибочные измерения. Потому что первая фильтрация уничтожала все решения. 
Теперь исправлено. На домашнем компьютере был заметно больше 500 мс.

2859844 - offset - единственное решение для "person3322"
5635302 - ??

535, 524 мс. - вот время, которое теперь правильно отражает результаты.


============ На рабочем компьютере
стало 278 мс. на 10000 запросов.
без загрузки 224-226 мс.

Возможно, пока этого достаточно. Для уменьшения "нагрузки" по кодированию можно применить 
следующие способы:
1) заранее кодировать предикаты
2) Сделать кеш кодирования. Кстати, хотелось бы измерить скрость работы такого кеша.
3) Объявить конкурс на улучшение скорости кодирования. Кажется, там есть резервы для улучшений.

Для использовании шкалы в оперативной памяти, результаты получились близкие, но минимальные
сместились до 197-198 мс.

============ На добмашем компьютере
522 после загрузки
517 без загрузки

20150603 07:05
Немного разошелся в синхронизации данного проекта. Вчера забыл дома сделать коммит. А потом 
на работе по-памяти восстанавливал текущее состояние. Сегодня сделал дома коммит, теперь надо 
аккуратно синхронизовать проект. Благо изменений мало и они в небольшом количестве мест.

Синхронизировал, сейчас сделаю коммит и все остальное...

Вчера также продумал схему реализации нового индекса. Надо бы его как-то назвать. Может - двухстадийный?
Как-то некрасиво... 

Смысл построения следующий
--------------------------
Как всегда, есть опорная таблица (последовательность элементов). Как всегда, есть индексный массив. 
Причем он может быть или не быть с дополнительным значением в записи элемента. Пусть пока нет дополнения,
есть "чистый" набор offset'ов. Причем упорядочивание индексного массива делается по двухстадийной 
функции упорядочивания. Первая стадия определяется ключевой функцией GenKey1(elem), имеющей (пока)
целочисленное значение. При равенстве значений GenKey1, упорядочивание ведется функцией GenKey2(elem),
имеющей или целочисленное значение или значение имеющее целочисленный полуключ (хеш). 

В казчестве примера, будем иметь ввиду реализацию RDF Triple Store - триплетной памяти.
Сопоставим первому генератору поле p, а второму генератору поле s или o, мы выстроили индекс на реализацию
доступа ps или po. Создадим добавление к "классическому" индексу такое, что мы также сможем иметь доступ
p, s и не очень эффективный pso. Для этого, достаточно создать массив целых, по одному элементу на первый ключ.
[i], причем целое означает номер в индекном массиве, с которого начинается очередной ключ. Соответственно, 
по паре соседних значений, легко получается диапазон {start, number} в индексном массиве, соответствующий
какому-то значению первичного ключа. Кстати, в диапазоне всегда как минимум, один элемент. 

Итак, есть последовательность (набор) элементов tab=[e/i], эти элементы достапны по массиву ссылок refs=[off/i],
а также есть массив (другого размера) groups=[start/j].
Массив ссылок refs состоит из всех offset'ов для элементов e/i набора tab. Ссылки упорядочены так, что они 
упорядочивают элементы опорной таблицы сначала по GenKey1(e/i), а потом по GenKey2(e/i). Массив groups
содержит начала однородных (одинаковых) по GenKey1 элементов и упорядочены по значению start. Также и по 
значению первого ключа (почему?).

Первично, такой индекс направлен на представление наборов элементов, удовлетворяющих совпадению по p, ps, s. 
В последнем случае, перебираются поски ps для всех p. Вначале идет нахождение нужного p. Это можно сделать
на основе упорядоченности groups по значению первого ключа, т.е. p. Можно произвести бинарный поиск или если
количество разных p мало, то можно создать массив в оперативной памяти и там искать хоть перебором. В результате,
находим start/j0 и вычисляем number/j0. А в этом диапазоне индексного массива, можно поискать нужные значения
опять же бинарным поиском.

Есть богатые возможности оптимизации данной схемы. Причем как в части ускорения поиска, так и в части ускорения 
вычисления индекса. 
1. Можно в индексном массиве сохранять также значение вторичного ключа. Естественно, вторичный ключ отсортирован
для каждого диапазона отдельно.
2. В массиве групп, можно хранить дополнительную информацию, напр. перове и последнее значения воричного ключа.
Кроме того, к массиву групп, можно добавиль шкалу. 
3. Для основного индексного массива можно предложить схему добавления шкалы. Идея предложения заключается в
том, что шкала выстраивается отдельно для каждого диапазона. Причем размер шкалы для диапазона устанавливается 
соответствующим, в частности равным, размеру диапазона. И тогда шкалу можно разместить непосредственно в
индексном массиве.

12:53 Рабочий компьютер
Вроде несложно. Главное, не ошибиться в формулах...

20150604 03:32
Что-то не спится, решил поработать. Тем более, что вчера болела голова и я не смо продвинуться в разработке. 

Замысел следующий. Я буду создавать программу ШАГ ЗА ШАГОМ. Сначала надо сделать просто индекс, который построен
двух генераторах ключей. Ну это - совсем обычно. Потом "приделать" массив групп. Ну и так далее... Кажется
важным создать систему тестирования, которая будет контролировать правильность обработки и измерять временные
характеристики. Что-ж - в добрый путь!

ВНИМАНИЕ: надо будет разобраться с построением Build и перестроением индексов. В частности со схемой регистрации 
и автокоррекции.

Первый результат поиска (рабочий компьютер): 10000 имен по случайно заданным идентификаторам персон 1563 мс.

Буду работать над уменьшением!

1547 мс. из них 220 мс на кодирование. Это процентов 15, довольно много.

Что теперь? 
Теперь надо сделать структуру (массив), хранящую индексы начал групп с одинаковым предикатом.

21:13 Домашний компьютер

3921 мс. - такова скорость выборки имен 10 тыс. персон. Это в 2.5 раз дольше, чем на работе.

Сначала делаю базовую структуру хранения групп. Это будет последовательность целых индексов массива refs
Это уже можно будет использовать.

20150605 10:09 Рабочий компрьютер
Надеюсь сегодня продвинуться. Чем дальше, тем лучше.

Как-то я запутался в использовании массива (начал) групп. Надо сделать по-другому. Надо сразу формировать
словарь. Все равно, для эффективности, этот словарь предусмотрен. Пусть будет:
Dictionary<int,Diapason>

3303 мс. Время выборки 10 тыс. персон уменьшилось за счет выделения групп по предикатам.

20150606 08:08
В 6 утра надо было начинать работу, тогда бы было 4 раза '06'. Сегодня день рождения мамы - 88 лет!

Намечу план на блишайшее будущее. Для начала, надо расширить (пока) одним целочисленным полем
индексный массив. Это поле использовать для сортировок и доступа (поиска). Посмотреть получающиеся
характеристики. Проверить гипотезу о том, что раздельная сортировка сначала по первому ключу, а потом
по второму, может положительно повлиять на скорость подготовки данных. 

Кажется, это можно сделать быстро. А потом - самое гдавное и не слишком тривиальное - добавление
вторым дополнительным полем или отдельной структурой "мультишкалы". Отдельной структурой имеет смысл по 
следующим причинам: во-первых, горизонтальные связи в индексном массиве почти не используются, во-вторых,
это потенциальная экономия памяти для случая, когда возможен смешанный режим наботы индекса в связи с его
наличием или отсутствием. Опять же размер шкалы у меня обычно в 30-60 раз был меньше. Есть о чем подумать.

Сейчас попробую проверить возможность разделить сортировку индекса на две фазы.
Монолитно, время сортировки - 18 сек.

Выполнение первой фазы - сортировки по первому ключу заняло 2.3 сек. Похоже, можно пробовать дальше. 

Теперь надо найти возможность построить массив групп. Вроде, проблем нет, можно его даже проще построить. 

Что-то не то. Добавление вычисления групп, привело к увеличению времени до 14 сек.
Нашел, теперь нормальные 2.7 сек. Дело было в особенности организации цикла и доступа к полям ячееек.

Сделал несколько по-новому. В один этап, но с сохранением и первого ключа и второго ключа/полуключа
в индексном массиве. Теперь времена получаются следующие:
Загрузка и таблица имен 6 сек.
Создание индексов 6.76 сек. (6.6)

Похоже на правильный результат. Что-то вычисляет... Проверить бы надо...

Теперь попробую использовать новую констукцию индекса для ускорения поиска. 

Вроде, эффект есть и заметный. Те же самые 10 тыс. запросов были выполнены за 1663 мс. Ранее было под 4 сек...

Ура! Проверил, вроде работает. Осталось добавить шкалы и "поколдовать" с работой "от объекта".

20150607 05:17
Я добрался до шкалы. Рассматривая код ScaleMemory, я понял, что хорошо бы поработать над абстракцией шкалы.

Итак, пусть есть упорядоченная по некоторому ключу последовательность. А точнее - подпоследовательность,
начинающаяся с индекса start и в количестве number элементов. Функция порядка - числовая, у ключевого
значения есть минимум, достигающийся на первом элементе и максимум, достигающийся на последнем. Для
помощи в поиске по ключевому значению (обобщение - по диапазону значений), создается функция, которая по
этому значению, возвращает диапазон индексов элементов, в которых возможно имеется значение, причем в 
элементах вне диапазона, значения точно нет. Пустой диапазон означает, что решений нет. 

ВНИМАНИЕ: похоже в текущей реализации вычисления шкалы есть ошибка во фрашменте "// Заполнение начал диапазонов" 
В первую ячейку шкалы записывается то, что должно быть записано во вторую и т.д.

Сейчас попробую встроить ScaleInMemory в решение. Текущий вариант: загрузка 6481 + индекс 6871 = 13.5 сек,
10 тыс имен персон 1733 мс.

Со включением шкалы, время уменьшилось, но не так сильно, как я ожидал
10 тыс имен персон 1093 мс.

Вроде немного дольше стал строиться индекс 10 сек. А может это случайно. Я пока не потключал построения 
"старого" словаря, хотя он должен втроиться довольно быстро.

При повторном построении, все сработало как всегда: загрузка 6040, индекс 7052, 10К имен 1096 объем БД 45.1 Мб.

Хочу понять, такие результаты это хорошо или плохо?
Еще раз проверяю TestStandard: загрузка и индексирование 9429, Объем БД 12.6 Мб. - это с тремя (!) индексами.
Выборка 1000 персон 58, 1000 фоток 95. 1000 портретов 208. По портретам сказать ничего не могу, но по персонам
похоже всего раза в 2 в триплетном варианте хуже. 

При следующей загрузке, результаты остались приблизительно теми же, но уменьшилось время вычисления 1000 
фоток до 45 мс. Общего вывода это не меняет. 

Сделал po-индекс. Пока непонятно работает ли. Но создается довольно долго 91 сек. Всего загрузка и создание 
двух индексов выполнялась 105 сек. Объем БД 60.3 Мб.

20150608 14:04 Рабочий компьютер
Индекс сделал, но что-то он плохо работает. Возможно совсем не работает. Надо бы как-то отладиться.
Некоторые впечатления. Во-первых, нет уверенности, что Hash-функция для объектных вариантов работает. 
Во-вторых, также нет уверенности, что шкала работает. Во всех вариантах...

Исправил пару ошибок, теперь вроде заработало! Загрузку удалось сделать быстрее. И обратные ссылки вычисляет.

Тестовый прогон. Загрузка и построение индексов 16.8 сек., Объем БД 60.3 Мб. 10 тыс. прямых свойств 470 мс.
количество обратных 11

Попробую приблизить тестирование к вычислению портрета.

На самом деле, кодирование идентификаторов выполняется довольно долго. 221-258 мс. на 10000. Надо бы ускорять, но это - потом.

262, 232, 254 - это после добавления new OV_iriint(iid, null);

10 тыс. обратных отношений получаются за 850-882 мс. В среднем - 6 обратных решений.
1133, 1084, 1072 после Dereference
2463 после SelectMany
2663, 2638 после вычисления объекта
4315, 4371 После вычисления предикатов name
4521, 4547 В итоге!

Получилось как у Виртуозо! Это хорошо?

Пропустил тест на 400 тыс персон. Загрузка+ 224 сек., поле name персон 656 мс. на 10 тыс. Портреты 4763 на 10 тыс. 
Объем базы данных 608 Мб.
Уже лучше Виртуозо!
1 млн. персон. Загрузка+ 635 сек., Объем БД 1.49 Гб, 10 тыс портретов 4579 мс.

Получилось несколько лучше Виртуозо, несколько лучше решения GaGraphStringBased. Но раз в 5 недотягивает до 
лучшего (Standard3TabsInt 86, 91 мс.). Я ожидал большего... Но еще можно поработать и пооптимизировать. 
 
В решении 3 раза применяется Dereference. Добавляется по 200 мс. Итого 600 - это же процентов 13! Не так много,
но из этих добавок накаливается итоговый результат.  

20150610 05:25
Сейчас пытаюсь осмыслить ситуацию и сформировать план действий. О чем идет речь? Речь идет о разнице 
производительности обработки (в тестах - одних и тех же) данных для моделей таблиц и триплетов. Вторая
модель работала в 10 раз хуже, сейчас - в 4-5 раз хуже. Кажется, что это все же существенно больше,
чем должно быть. А должно быть - раза в 2. 

Вчерашние измерения показали, что разница в производительностях присутствует (естественно) и на уровне
весьма базовых процедур выборки. Я хочу внимательно изучить в чем разница и откуда берутся существенные
отличия во временах обработки. 

На рабочем окмпьюетере было:
Standard3TabsInt:
10K persons 199 ms
10K photo_docs 178 ms
10K portraits 867 ms

TripleSetInt
10K person names 605, 677 ms
10K portraits 4669, 4665 ms

Итак, ДОМАШНИЙ КОМПЬЮТЕР
Повторю измерения, а потом буду разбираться.

TripleSetInt
10K person names 1091 ms
10K portraits 10274 ms

Standard3TabsInt:
10K persons 449 ms
10K photo_docs 431 ms
10K portraits 2066 ms

Есть разница: для персон ускорение - чуть больше, чем в 2 раза, для портретов - почти в 5! 
Попробую взять первую процедуру портретов, каким будет ускорение?
381 мс. для "стандарта"
1936 мс. для триплетов. 
- в 4.3 раза. Это много, хотя и не  так чтобы очень...
Таким образом, надо сравнить (плохой) доступ g.GetTriplesWithPredicateObject(ireflected, ov)
с (хорошим) доступом index_reflected.GetAllByKey(code)

Для хорошего случая, выделяется диапазонпо шкале и ключевой фрагмент:
            var query = index_cell.Root.BinarySearchAll(start, number, ent =>
            {
                var ob = (Tkey)(ent.Field(0).Get());
                return ob.CompareTo(key);
            });
            return query.Select(ent =>
            {
                entry1.offset = (long)ent.Field(1).Get();
                return entry1;
            });

А для "плохого" варианта ключевой фрагмен более сложный:
            var query = index_cell.Root.BinarySearchAll(dia.start, dia.numb, ent =>
            {
                object[] va = (object[])ent.Get();
                int hk = (int)va[2];
                int cmp = hk.CompareTo(hkey);
                if (cmp != 0) return cmp;
                long off = (long)va[0];
                entry.offset = off;
                object ob = entry.Get();
                cmp = Key2Producer(ob).CompareTo(key2);
                return cmp;
            })
            .ToArray()
            ;
            return query.Select(ent =>
            {
                long off = (long)ent.Field(0).Get();
                entry.offset = off;
                return entry;
            });
Попытка убрать .ToArray() "сбрасывает" сотенку миллисекунд общего времени, получается 1900 мс.
Все же здесь есть "несуразность" - мы дважды вычисляем entry и даже (часто) дважды его разыменовываем.
Первый раз при вычислении ключа k2, второй - уже после (вне) этого фрагмента. Еще одна "несуразность"
в том, что на предыдущем этапе мы должны были выявить диапазон, в котором полуключ одинаков. Это
правда не совсем верно, посколько для шкалы допускается что-то другое... 
Попробую воспроизвести вычисления постепенно, шаг за шагом. 

Итак, начали. 
1. Пустой цикл (почти пустой, есть кодирование и создание объекта) 533
2. Добавлено вычисление локального диапазона 532 
3. При сканировании элементов, определенных локальными диапазонами, выявилось почти 2 млн., т.е. около 200
на один диапазон. Попробую комбинировать поиск диапазона и сканирование с поиском.
Пока удержался на уровне 2022 мс. А уже вычислено объектное представление триплета.  
Честно говоря, достижение не слишком впечатляет. Две первых фазы, включая разименование, выполнялись ранее
за 2600, 2497 мс.  
4. Подключаем переход к  5150 мс. <-> По сравнению с 5636, как ранее. Буду улучшать эту часть. 
Снова добрался до возможного отказа от разыменования. Попробую.
Опять получилось не сильно заметно 5133 <-> 5816 
Будет еще одно разыменование.
5. Получилось 8721 <-> 9948

Итак, получился суммарный выигрыш почти 1300 мс. Это наверное 13% - кое-что.
Теперь построение 10 тыс. портретов занимает 8700 мс. то есть в 4 раза дольше, чем "стандартный" вариант.
Но сделать быстрее уже довольно трудно. 

20150612 12:41
День России! Звучит красиво и гордо!

Сегодя я хочу славно поработать. Надеюсь отобразить полученное решение в общую с Сергеем Sparql-обстановку. 

Сейчас надо обдумать весьма важный вопрос - как насчет слабой динамики? 
Очевидно, то также как и раньше. Слабую динамику первично поддерживает TableView, а индексы корректируют
свою динамическую часть по присылаемым событиям. Еще индексы надо регистрировать в опорной таблице. 
Похоже, конструкцию нао сделать полностью аналогичной той, которая получалась использованием универсального
индекса. Посмотрю на то самое построение. 

ВНИМАНИЕ: я не уверен, что учтен вариант, когда полуключ2 является ключем не надо лезть и вычислять key2

20150613 12:17
Продолжаю работать над программой. Вроде, заработала. То есть, заработало то, что вчера-позавчера уже работало,
но сейчас я привожу к унифицированному интерфейсу IGraph.

Сейчас доделаю другие методы и начну плотно работать с Сергеем.

20150630 10:54
Последний день июня, как быстро летит время...

Сегодня настала пора написать векторный индекс. Кажется, в прошлый раз я его делал использую скалярный индекс, 
так что трудностей не предвидется. Тем не менее, надо сделать такой индекс максимально ответственно. Во-первых,
потому что он мне понадобится на ЛШЮП, во-вторых, есть идея сделать новый (!) вариант RDF-машины. Я хочу снова 
попробовать сгруппировать триплеты в записи и к ним сделать два индекса: стандартный (скалярный) индекс на записи
и второй - каскадный индекс обратных отношений (p, o). Идея следующая: а) группирование компактизирует данные;
б) выбоки s - оптимизированы, выборки p и po - оптимизированы, выборки sp, spo, so будут довольно хорошими поскольку
вся информация сгруппирована по s; в) потенциально, можно обойтись без "внешней" таблицы имен, добавив в запись 
поле с идентификатором и добавив один индекс по этому индентификатору. Последнее еще больше компактизирует данные.
В компактном варианте хранения достаточно будет хранить только опорную таблицу. 

Вообще-то я так все расписал, что мне реально захотелось сделать в "потенциальном" варианте. Если еще использовать 
сполшную нумерацию, то доступ по s будет очень быстрым. Таблицу делаю следующим образом. Беру все триплеты, 
сортирую их по s (может по p вторично). 

Другой вариант, беру триплеты из источника, формирую (все же) таблицу имен (строка-код). Снова беру триплеты из 
источника, преобразую (кодирую) триплеты, выстраиваю последовательность. Сортирую последовательность по кодам 
s. Переписываю триплеты, при этом, группирую треплеты в записи, добавляю строку кода, возможно выделяю тип записи.
Записи получаются что-то вроде:
{code: int, iri: string, type: int, triples: [pred: int, obj: ObjectVariants]}
Для каких-то кодов, может оказаться множество триплетов с данным s пустым. Такие множества надо также помещать в
опорную таблицу. При этом нумерация будет получаться сплошной.  

Чтобы отказаться от таблицы имен, потребуется индекс опорной таблицы по коду и другой индекс таблицы имен - 
по идентификатору iri. Наверное здесь можно сэкономить на том, что можно переработать индекс таблицы имен в этот.
Можно еще сэкономить если индекс выстроить в виде код-полуключ (2 целых) и offset формировать из кода. Но это
нарушит регулярность. А первую оптимизацию наверное можно сделать. 

В результате будет опорная таблица записей и два индекса (по коду и по iri). Теперь сделаем векторный индекс путем
отображения записей в последовательность {code, pred, objiri}. Причем будут учитываться только объектные триплеты.
Если эту последовательнсть отсортировать по po, то получится индекс, позволяющий получать группы кодов, для которых
зафиксированы или p или po, или, перебором, o.

20150701 07:34
Вот и дождался июля... 
Сделаю оценку плотности данных при рассматриваемом подходе. Самое значительное в хранимых данных - триплеты в записи.
Для объектных триплетов это будет предикат(целое) + тег(байт) + objiri(целое). Кроме того, для каждого объектного
триплета, будет еще три целых в индексной таблице. Ну еще идексы, размером с количество узлов. Итого: 
9 байтов + 15 байтов (datatype) + 12 (обратный индекс) = 36 байтов на 2 триплета. Ну еще процентов 20 добавится за
счет переходных процессов. Итого, 22 байта. Миллиард триплетов будет обрабатываться не очень быстро, но четверть 
миллиарда - (очень) быстро. Может даже половина...

20150702 07:12
Кстати, насчет "не очень быстро" - предложенная структура дополнительно хороша тем, что разбивается на "главную"
последовательность записей и "вспомогательные" индексы. При этом, похоже опорная последовательность будет доминировать
по объему. А это, в частности означает, что если памяти не будет хватать, опорную последовательность можно не загружать 
в память и при этом общая производительность останется на приемлемом уровне в "одно чтение с диска" на один запрос. 
Есть правда и проблемные моменты. Например то, что большие (строковые или бинарные) данные будут "мешаться" для 
размещения в ОЗУ. Правда конструкция ObjectVariants позволяет ввести некоторые дополнительные варианты и компенсировать
проблему. 

Еще одно пришедшее соображение. Я все думал о векторном индексе. Сначала на элементах последовательности вычисляется
векторная функция, результаты агрегируются в последовательность, а потом эта последовательность подвергается 
индексированию. Так вот соображение заключается в том, что для случаев выровненных данных возможно "автоиндексирование",
т.е. просто сортировка этой последовательность. Причем такая сортировка не мешает построению других индексов, поскольку
порядок элементов опорной последовательности при индексации не существенен. Надо только разобраться в некоторых моментах.
Первый - шкалирование. Второй - слабая динамика. Шкалирование похоже вообще не создает проблем. А вот слабая динамика -
непонятна. Там главная операция - уничтожение записи. При этом мы помечаем запись признаком deleted. В принципе, все 
значения векторной фукнции на этом элементе также должны быть уничтожены. Наверное, помечены как deleted. А это не 
получается сделать без полного перебора значений векторного индекса. Значит смотреть на deleted надо позже, при 
обработке. Для оценки возможности такого учета, рассмотрим поисковый запрос, который делается к векторному индексу.
Это нахождение всех записей, на которых среди значений векторной функции имеется данное значение. Соответственно, 
поток указателей на такие записи можно будет подвергать фильтрованию на значение поля deleted. А как же добавление?
Добавляется запись. На ней вычисляется векторная функция и указатели на опорную последовательность будут добавляться
к спискам значений в словарях, управляемых ключевым значением. 

Нерешенным осталась проблема, заключающаяся в том, что мы бы хотели отказаться от указателя (offset) на элемент опорной
последовательности в пользу индекса этой последовательности. Все же выигрыш в 4 байта!

Есть некоторая тонкость по векторному индексу. Рассмотрим самый общий случай: последовательность элементов и векторная
функция, определенная на элементах порождает сравнимые значения. Тогда к опорной последовательности добавляется векторно-
индексная последовательность элементов вида (offset записи, значение функции). Тонкость заключается в том, что теперь 
мы эту новую последовательность можем оформить как новую опорную и индексировать ее по значению ключа (значению фукнции).
Соответственно, в новой опорной таблице может быть "столбец" deleted и управление им. Управление может выглядеть следующим
образом. Если внешняя запись подвергается уничтожению, то группа элементов индексный таблицы, порожденных от этого элемента,
может быть отмечена как deleted. Соответственно, добавление новой записи, просто добавляет группу элементов. Альтернативно
мы не создаем столбца deleted для векторного индекса, а уничтоженные смотрим в получаеющемся наборе записей. Добавление
делаем также через добавление в индексную последовательность и коррекцию индекса уже этой последовательности. 

Получается несколько громоздко, поскольку есть массив значений и новый индекс к нему. С другой строны, текстовый поиск
требует именно подобного решения. Для триплетов есть схема, в которой мы также лишаемся выровнености массива ключевых 
значений. Например, если индексировать полностью по объекту (как сейчас). 

Кстати, я подумал о том, что "базовые" решения могут быть хорошо востребованы в in-memory режимах. Ранее, решение типа 
последовательности offset'ов было не очень выгодным из-за удвоения-утроения в количестве доступов к файлам. Если количество
доступов к файлам перестает быть критичным моментом, то вопросы эффективности можно будет пересматривать в сторону экономии 
пространства. 

20150703 11:38
Глубокое обдумывание описанной идеи показало, что я не учел ряд обстоятельств, а с их учетом - она НИКУДА не годится!
Действительно, все неплохо по прямым свойствам и отношениям. Но по обратным свойствам и отношениям - ве гораздо хуже.
Действительно, я учитывал только обратные объектные отношения. Но надо индексировать и свойства данных. Если не отделять
такое индексирование от объектных свойств, то получится в чистом виде множество троек (s p o) и индексирование множества 
по o или po. Это воспроизводит половину "картины" индексации, от которой я хотел уйти. Причем в худшем варианте. Теперь у
нас есть целостный граф (включая литералы) записей и целостный этот же граф в виде триплетов. Это дублирование, это
никуда не годится! 

С другой стороны, меня заинтересовала минимизация занимаемого базой данных места. Будем считать. Для 1 млн. триплетов.
Таблица имен 8.11 Мб., индекс offsets 2.74 Мб., индекс по строкам видимо также 2.74 Мб. Опорная таблица триплетов 11.8 Мб.
Пара ее индексов ps и po, возхможно в сумме 15.2 Мб. Итого - 40.6 Мб. Сейчас - 60.3. Не такая уж большая разница, но все же.
Тянет на четверть миллиарда по эффективной обработке. Теоретически, если заменить двойные целые в указателях на простые
целые, получится 30.25 Мб. Можно уже "мечтать" о половинке миллиарда. Как я понимаю, такая замена не всегда возможна, напр.
если значения не выровнены и не кратны чему-то. 

20150704 10:35
Все же жаль идею... Но у меня есть более существенная. Это in-memory cache для ячеек. Все пытаюсь настроиться на это дело.
Даже попробовать боюсь. А все потому, что не хочу "курочить" существующие решения по ячейкам и указателям. Попробую провести
эксперимент вне пакета PolarDB, пока вне...

Как это будет выглядеть? Пусть есть ячейка PaCell2, расширяющая стандартную PaCell. Расширение делаем по-минимуму. Есть 
дополнение к структуре ячейки поля cache, обладающаего интерфейсом ICellCache. Это поле может быть null или иметь какое-то
значение. У кеша есть статус inactive, unused, activating, active. Начальное состояние кеша inactive. 
Значение null, соответствует состоянию unused. Когда режим active, то это означает, что можно пользоваться кешевой копией
ячейки. Пока манипуляции с записями можно не производить. 

20150705 10:11
Возникли затруднения в способе введения новой функциональности. В принципе, базовая идея сделать новый класс PaCell2, 
который наследует свойства PaCell и начать переписывать некоторые методы. А потом новым классом пользоваться как старым. 
Возникшая проблема в том, что PaEntry, играющий ключевую роль к значениям ячейки, написан с элементами прямого использования
структуры PaCell. Поэтому, чтобы добиться эффекта, нужно переписыватьь также PaEntry. А его переписать в том же стиле через
расширение уже не получится, поскольку PaEntry много где используется. Надо решаться. Посмотрю как часто в определениях 
PaEntry встречаются работы с ячейками и какие это работы.

1 пропуск строки; 2 чтения длины последовательности; 2 чтения байта варианта; 1 Count() с двумя вариантами реализации;
1 Append(), рабтающий в Set(); 1 AppendElement()

TODO: Надо разобраться со Skip(). Я там то устанавливю offset, то беру предыдущий. А в GetPObject() я работаю в контексте
текущего указателя файла - это хорошо??? Кроме того, GetPObject() работает непосредственно на бинарном ридере. Это нам надо???

Вроде не так много. Вроде и логика не слишком тяжелая. Правда есть желание поменять часть логики.  
  
  

 

       

   



  
  

 
     
 

  




 

   
   

   













  

 

 